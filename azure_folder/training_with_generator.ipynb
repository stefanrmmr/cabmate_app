{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "print(azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1.34.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1634383819838
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "experiment_name = \"cab_training_experiment\"\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634383931384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datastore = ws.get_default_datastore()\n",
        "datastore.upload_files(files = ['./data/2020/combined_2020.csv'],\n",
        "                       target_path='dataset/', overwrite=True,\n",
        "                       show_progress=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 1 files\nUploading ./data/2020/combined_2020.csv\nUploaded ./data/2020/combined_2020.csv, 1 files out of an estimated total of 1\nUploaded 1 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_62cfa435f247470291148d0c9697a509"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634384046848
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = ''\n",
        "resource_group = 'cabResourceGroup'\n",
        "workspace_name = 'Cabalitics'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='cab_dataset_2020')\n",
        "dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                     year  month  day  weekday  trip_duration  \\\n2020-01-01 00:33:03  2020      1    1        3            288   \n2020-01-01 00:43:04  2020      1    1        3            445   \n2020-01-01 00:53:52  2020      1    1        3            371   \n2020-01-01 01:00:14  2020      1    1        3            291   \n2020-01-01 00:04:16  2020      1    1        3            138   \n...                   ...    ...  ...      ...            ...   \n2020-12-31 23:31:36  2020     12   31        4           1563   \n2020-12-31 23:05:33  2020     12   31        4            493   \n2020-12-31 23:48:43  2020     12   31        4            488   \n2020-12-31 23:57:39  2020     12   31        4            162   \n2020-12-31 23:24:08  2020     12   31        4            772   \n\n                    tpep_dropoff_datetime  trip_distance  PULocationID  \\\n2020-01-01 00:33:03   2020-01-01 00:33:03           1.20           238   \n2020-01-01 00:43:04   2020-01-01 00:43:04           1.20           239   \n2020-01-01 00:53:52   2020-01-01 00:53:52           0.60           238   \n2020-01-01 01:00:14   2020-01-01 01:00:14           0.80           238   \n2020-01-01 00:04:16   2020-01-01 00:04:16           0.00           193   \n...                                   ...            ...           ...   \n2020-12-31 23:31:36   2020-12-31 23:31:36          11.30           107   \n2020-12-31 23:05:33   2020-12-31 23:05:33           2.18           236   \n2020-12-31 23:48:43   2020-12-31 23:48:43           2.52           236   \n2020-12-31 23:57:39   2020-12-31 23:57:39           0.59           238   \n2020-12-31 23:24:08   2020-12-31 23:24:08           6.06            75   \n\n                     tip_amount  total_amount  \n2020-01-01 00:33:03        1.47         11.27  \n2020-01-01 00:43:04        1.50         12.30  \n2020-01-01 00:53:52        1.00         10.80  \n2020-01-01 01:00:14        1.36          8.16  \n2020-01-01 00:04:16        0.00          4.80  \n...                         ...           ...  \n2020-12-31 23:31:36        0.00         36.80  \n2020-12-31 23:05:33        2.56         15.36  \n2020-12-31 23:48:43        4.00         17.30  \n2020-12-31 23:57:39        2.08         10.38  \n2020-12-31 23:24:08        0.00         19.80  \n\n[23838931 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>weekday</th>\n      <th>trip_duration</th>\n      <th>tpep_dropoff_datetime</th>\n      <th>trip_distance</th>\n      <th>PULocationID</th>\n      <th>tip_amount</th>\n      <th>total_amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-01 00:33:03</th>\n      <td>2020</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>288</td>\n      <td>2020-01-01 00:33:03</td>\n      <td>1.20</td>\n      <td>238</td>\n      <td>1.47</td>\n      <td>11.27</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 00:43:04</th>\n      <td>2020</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>445</td>\n      <td>2020-01-01 00:43:04</td>\n      <td>1.20</td>\n      <td>239</td>\n      <td>1.50</td>\n      <td>12.30</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 00:53:52</th>\n      <td>2020</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>371</td>\n      <td>2020-01-01 00:53:52</td>\n      <td>0.60</td>\n      <td>238</td>\n      <td>1.00</td>\n      <td>10.80</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 01:00:14</th>\n      <td>2020</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>291</td>\n      <td>2020-01-01 01:00:14</td>\n      <td>0.80</td>\n      <td>238</td>\n      <td>1.36</td>\n      <td>8.16</td>\n    </tr>\n    <tr>\n      <th>2020-01-01 00:04:16</th>\n      <td>2020</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>138</td>\n      <td>2020-01-01 00:04:16</td>\n      <td>0.00</td>\n      <td>193</td>\n      <td>0.00</td>\n      <td>4.80</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 23:31:36</th>\n      <td>2020</td>\n      <td>12</td>\n      <td>31</td>\n      <td>4</td>\n      <td>1563</td>\n      <td>2020-12-31 23:31:36</td>\n      <td>11.30</td>\n      <td>107</td>\n      <td>0.00</td>\n      <td>36.80</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 23:05:33</th>\n      <td>2020</td>\n      <td>12</td>\n      <td>31</td>\n      <td>4</td>\n      <td>493</td>\n      <td>2020-12-31 23:05:33</td>\n      <td>2.18</td>\n      <td>236</td>\n      <td>2.56</td>\n      <td>15.36</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 23:48:43</th>\n      <td>2020</td>\n      <td>12</td>\n      <td>31</td>\n      <td>4</td>\n      <td>488</td>\n      <td>2020-12-31 23:48:43</td>\n      <td>2.52</td>\n      <td>236</td>\n      <td>4.00</td>\n      <td>17.30</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 23:57:39</th>\n      <td>2020</td>\n      <td>12</td>\n      <td>31</td>\n      <td>4</td>\n      <td>162</td>\n      <td>2020-12-31 23:57:39</td>\n      <td>0.59</td>\n      <td>238</td>\n      <td>2.08</td>\n      <td>10.38</td>\n    </tr>\n    <tr>\n      <th>2020-12-31 23:24:08</th>\n      <td>2020</td>\n      <td>12</td>\n      <td>31</td>\n      <td>4</td>\n      <td>772</td>\n      <td>2020-12-31 23:24:08</td>\n      <td>6.06</td>\n      <td>75</td>\n      <td>0.00</td>\n      <td>19.80</td>\n    </tr>\n  </tbody>\n</table>\n<p>23838931 rows × 10 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634384387919
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634384650174
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generator"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data, batch_size, num_batches):\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        #self.date_time_list = np.empty((self.batch_size, 4), int) #(year, month, day, timeslot)\n",
        "        self.num_batches = num_batches\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        #returns the number of batches per epoch\n",
        "        return self.num_batches\n",
        "    \n",
        "\n",
        "    def __getitem__(self, index): #__data_generation is redundant; could be done in this fn.\n",
        "        #Generate one batch of data\n",
        "        #index: index of the batch inside the epoch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X, y = self.__data_generation()\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        #updates indexes after each epoch\n",
        "        #indexes: the complete indexing during one epoch (num_batches * batch_size) - normal case: the whole dataset\n",
        "        self.indexes = np.arange(self.num_batches * self.batch_size)\n",
        "\n",
        "\n",
        "    def __data_generation(self):\n",
        "        start = pd.to_datetime('2020-01-01')\n",
        "        end = pd.to_datetime('2021-01-01')\n",
        "        random_date_list = self.random_dates(start, end)\n",
        "        #END CREATE RANDOM LIST OF DATES (SIZE: BATCH_SIZE)\n",
        "\n",
        "\n",
        "        date_filtered_subset = self.data.loc[(data.index <= end) & (data.index >= start)]\n",
        "        #END SELECT TIME-SLOT\n",
        "        x_data = np.zeros((self.batch_size, 265, 2, 4), int) #demand, month, weekday -» One-Hot encoded!\n",
        "        y_data = np.zeros((self.batch_size, 265, 5), float) #demand, fare(==revenue), tip, trip_dist, trip_duration\n",
        "\n",
        "        past_timestamps = np.arange(60, 0, -30)\n",
        "        #future_timestamps = np.arange(5, 30, 5) #TOO LOW\n",
        "\n",
        "        for b in range(self.batch_size):\n",
        "            weekday, month, time = random_date_list[b].weekday(), random_date_list[b].month, random_date_list[b].\n",
        "            x_data[b,:,:,1:] = [weekday, month]\n",
        "            #INPUT (X_DATA):\n",
        "            for d, delta in enumerate(past_timestamps):\n",
        "                start = random_date_list[b]-pd.Timedelta(minutes=delta) #replace 0 with b in batch_size\n",
        "                end = random_date_list[b]-pd.Timedelta(minutes=(delta-30)) #replace 0 with b in batch_size\n",
        "                temp_data = self.data.loc[(data.index <= end) & (data.index >= start)]\n",
        "\n",
        "                demand_list = temp_data['PULocationID'].value_counts()\n",
        "                #x_data[:,:,1:] = [random_date_list[0].weekday(), random_date_list[0].month]\n",
        "                for index, value in demand_list.items():\n",
        "                    x_data[b,(index-1),d,0] = value\n",
        "\n",
        "            #OUTPUT (Y_DATA):\n",
        "\n",
        "            start = random_date_list[b]+pd.Timedelta(minutes=5) #replace 0 with b in batch_size\n",
        "            end = random_date_list[b]+pd.Timedelta(minutes=30) #replace 0 with b in batch_size\n",
        "            temp_data = self.data.loc[(data.index <= end) & (data.index >= start)]\n",
        "\n",
        "            demand_list = temp_data['PULocationID'].value_counts()\n",
        "            pls = temp_data.groupby(['PULocationID']).mean()[['trip_duration', 'trip_distance', 'tip_amount', 'total_amount']]\n",
        "\n",
        "            for index, value in demand_list.items():\n",
        "                y_data[b,(index-1),0] = value\n",
        "\n",
        "            for index, row in pls.iterrows():\n",
        "                y_data[b,(index-1), 1:] = row\n",
        "\n",
        "        return x_data, y_data\n",
        "\n",
        "\n",
        "    \n",
        "    def random_dates(self, start, end):\n",
        "        #CREATE RANDOM LIST OF DATES (SIZE: BATCH_SIZE)\n",
        "        start_u = start.value//10**9\n",
        "        end_u = end.value//10**9\n",
        "\n",
        "        return pd.to_datetime(np.random.randint(start_u, end_u, self.batch_size), unit='s')"
      ],
      "outputs": [],
      "execution_count": 204,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634399578483
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import InputLayer, Lambda, Dropout, BatchNormalization, Dense, \\\n",
        "                                    Conv2DTranspose, Input, Activation, Conv2D, MaxPool2D, Reshape\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def fully_connected():\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(InputLayer(input_shape = (265, 2, 3)))\n",
        "\n",
        "    model.add(Dense(20, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(40, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(80, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(80, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(40, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(20, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Reshape((265,40)))\n",
        "\n",
        "    model.add(Dense((20), activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense((10), activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(5, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    model.add(Dense(5, name = 'output', activation='relu'))\n",
        "\n",
        "    model.compile(optimizer=Adam(10e-4),\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def res_based():\n",
        "    i = Input(shape = (265,2,3))\n",
        "    backbone = ResNet50(include_top = False, weights = None, input_tensor = i)\n",
        "\n",
        "    x = backbone.output\n",
        "    o = Dense((10), activation = 'relu') (x)\n",
        "    model = Model(inputs = i, outputs = x)\n",
        "\n",
        "    model.compile(optimizer=Adam(10e-2),\n",
        "                  loss='mean_squared_error',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = fully_connected()\n",
        "model.summary()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential_21\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_120 (Dense)            (None, 265, 2, 20)        80        \n_________________________________________________________________\nbatch_normalization_105 (Bat (None, 265, 2, 20)        80        \n_________________________________________________________________\ndropout_48 (Dropout)         (None, 265, 2, 20)        0         \n_________________________________________________________________\ndense_121 (Dense)            (None, 265, 2, 40)        840       \n_________________________________________________________________\nbatch_normalization_106 (Bat (None, 265, 2, 40)        160       \n_________________________________________________________________\ndense_122 (Dense)            (None, 265, 2, 80)        3280      \n_________________________________________________________________\nbatch_normalization_107 (Bat (None, 265, 2, 80)        320       \n_________________________________________________________________\ndense_123 (Dense)            (None, 265, 2, 80)        6480      \n_________________________________________________________________\nbatch_normalization_108 (Bat (None, 265, 2, 80)        320       \n_________________________________________________________________\ndense_124 (Dense)            (None, 265, 2, 40)        3240      \n_________________________________________________________________\nbatch_normalization_109 (Bat (None, 265, 2, 40)        160       \n_________________________________________________________________\ndense_125 (Dense)            (None, 265, 2, 20)        820       \n_________________________________________________________________\nbatch_normalization_110 (Bat (None, 265, 2, 20)        80        \n_________________________________________________________________\nreshape_11 (Reshape)         (None, 265, 40)           0         \n_________________________________________________________________\ndense_126 (Dense)            (None, 265, 20)           820       \n_________________________________________________________________\nbatch_normalization_111 (Bat (None, 265, 20)           80        \n_________________________________________________________________\ndropout_49 (Dropout)         (None, 265, 20)           0         \n_________________________________________________________________\ndense_127 (Dense)            (None, 265, 10)           210       \n_________________________________________________________________\nbatch_normalization_112 (Bat (None, 265, 10)           40        \n_________________________________________________________________\ndropout_50 (Dropout)         (None, 265, 10)           0         \n_________________________________________________________________\ndense_128 (Dense)            (None, 265, 5)            55        \n_________________________________________________________________\nbatch_normalization_113 (Bat (None, 265, 5)            20        \n_________________________________________________________________\ndropout_51 (Dropout)         (None, 265, 5)            0         \n_________________________________________________________________\noutput (Dense)               (None, 265, 5)            30        \n=================================================================\nTotal params: 17,115\nTrainable params: 16,485\nNon-trainable params: 630\n_________________________________________________________________\n"
        }
      ],
      "execution_count": 233,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1634403679731
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = DataGenerator(data, 32, 10)\n",
        "model_history = model.fit(x=generator,\n",
        "                          epochs=30,\n",
        "                          verbose=1,\n",
        "                          )"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 10 steps\nEpoch 1/30\n10/10 [==============================] - 141s 14s/step - loss: 638052.0312 - accuracy: 0.0607\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2/30\n10/10 [==============================] - 134s 13s/step - loss: 596839.0875 - accuracy: 0.0699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3/30\n10/10 [==============================] - 126s 13s/step - loss: 427373.5875 - accuracy: 0.0772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4/30\n10/10 [==============================] - 125s 13s/step - loss: 637950.1031 - accuracy: 0.0890\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/30\n10/10 [==============================] - 125s 12s/step - loss: 564041.0203 - accuracy: 0.1033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6/30\n10/10 [==============================] - 131s 13s/step - loss: 377880.9297 - accuracy: 0.1133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7/30\n10/10 [==============================] - 131s 13s/step - loss: 425159.0078 - accuracy: 0.1246\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8/30\n10/10 [==============================] - 133s 13s/step - loss: 398786.9422 - accuracy: 0.1425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9/30\n10/10 [==============================] - 131s 13s/step - loss: 429935.0852 - accuracy: 0.1702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10/30\n10/10 [==============================] - 132s 13s/step - loss: 416152.4797 - accuracy: 0.1807\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11/30\n10/10 [==============================] - 128s 13s/step - loss: 306429.6773 - accuracy: 0.2059\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12/30\n10/10 [==============================] - 131s 13s/step - loss: 503743.2812 - accuracy: 0.2152\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n10/10 [==============================] - 129s 13s/step - loss: 446155.2047 - accuracy: 0.2197\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14/30\n10/10 [==============================] - 128s 13s/step - loss: 252322.4359 - accuracy: 0.2259\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15/30\n10/10 [==============================] - 132s 13s/step - loss: 567551.5336 - accuracy: 0.2364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16/30\n10/10 [==============================] - 128s 13s/step - loss: 422284.9891 - accuracy: 0.2362\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17/30\n10/10 [==============================] - 128s 13s/step - loss: 466072.2172 - accuracy: 0.2408\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18/30\n10/10 [==============================] - 141s 14s/step - loss: 531565.9664 - accuracy: 0.2455\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19/30\n10/10 [==============================] - 125s 12s/step - loss: 509213.2703 - accuracy: 0.2499\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20/30\n10/10 [==============================] - 127s 13s/step - loss: 499994.2156 - accuracy: 0.2508\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21/30\n10/10 [==============================] - 125s 13s/step - loss: 548680.2445 - accuracy: 0.2587\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22/30\n10/10 [==============================] - 126s 13s/step - loss: 497738.2734 - accuracy: 0.2646\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23/30\n10/10 [==============================] - 128s 13s/step - loss: 631246.9531 - accuracy: 0.2649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24/30\n10/10 [==============================] - 127s 13s/step - loss: 459077.3672 - accuracy: 0.2668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25/30\n10/10 [==============================] - 132s 13s/step - loss: 590598.7266 - accuracy: 0.2725\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26/30\n 5/10 [==============>...............] - ETA: 1:04 - loss: 805772.8594 - accuracy: 0.2781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 6/10 [=================>............] - ETA: 51s - loss: 700233.0807 - accuracy: 0.2790 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 7/10 [====================>.........] - ETA: 38s - loss: 768707.9442 - accuracy: 0.2778\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 8/10 [=======================>......] - ETA: 25s - loss: 768707.9442 - accuracy: 0.2778"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-234-a113a085ce0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m model_history = model.fit(x=generator,\n\u001b[1;32m      3\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                           )\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 234,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}